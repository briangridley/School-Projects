---
title: "Final Exam Solution"
author: "Brian Gridley"
date: "December 14, 2017"
output: pdf_document
---

1. You roll five six-sided dice. Write a script in R to calculate the probability of getting between 15 and
20 (inclusive) as the total amount of your roll (ie, the sum when you add up what is showing on all five
dice). Exact solutions are preferable but approximate solutions are ok as long as they are precise.

```{r}
library(tidyverse)

# this creates the combination of all posible rolls
five_dice <- expand.grid( 1:6, 1:6, 1:6, 1:6, 1:6 )

# this calculates the sums of each possible roll
five_dice_sums <- rowSums(five_dice)

# this counts all the rolls that we're interested in (where the sum is between 15 and 20)
sum(five_dice_sums >= 15 & five_dice_sums <= 20)

# calculating probability
sum(five_dice_sums >= 15 & five_dice_sums <= 20)/length(five_dice_sums)
```

The probability is 0.5570988

2. Create a simulated dataset of 100 observations, where x is a random normal variable with mean 0 and
standard deviation 1, and y = 0.1 + 2 ??? x + e, where epsilon is also a random normal error with mean 0
and sd 1. (One reminder: remember that in creating simulated data with, say, 100 observations, you
need to use rnorm(100) for epsilon, not rnorm(1), to ensure that each observation gets a different
error.)

```{r}
set.seed(17)
x <- rnorm(100, 0, 1)

set.seed(18)
epsilon <- rnorm(100,0,1)

y <- 0.1 + 2*x + epsilon
```


a. Perform a t test for whether the mean of Y equals the mean of X using R.

```{r}
t.test(x, y)
```
```{r}
# rejection region with 2-tailed test
qt(0.975,140)
qt(0.025,140)
```

The rejection range is any t statistic greater than 1.977 or less than -1.977. The t-statistic from this study (0.15895) does not fall in the rejection range (using a p-value of 0.05) so we cannot reject the null hypothesis. The p-value also tells us that we cannot reject the null. We cannot say that the two means are sufficiently different.


b. Now perform this test by hand using just the first 5 observations. Please write out all your steps in
latex.

```{r}
# take first 5 observations from x and y
xfirst5 <- x[1:5]
yfirst5 <- y[1:5]

xfirst5
yfirst5
```

$$test\ statistic = \frac{\overline{y}_{xfirst5} - \overline{y}_{yfirst5}}{se_{diff}}$$
$$se_{diff} = \sqrt{se_{1}^{2} + se_{2}^{2} }$$
$$se_{diff} = \sqrt{(\frac{0.7032065}{\sqrt{5}})^2+(\frac{1.762748}{\sqrt{5}})^2} = \sqrt{(0.3144835)^2+(0.7883251)^2} = 0.8487381$$
$$test\ statistic = \frac{(-0.2745619)-(-0.3468177)}{0.8487381} = 0.08513318$$

```{r}
mean(xfirst5)
mean(yfirst5)

#se's
se_x <- sd(xfirst5)/(sqrt(5))
se_y <- sd(yfirst5)/(sqrt(5))

#se diff
se_diff <- sqrt((se_x^2)+(se_y^2))

# t-statistic
(mean(xfirst5)-mean(yfirst5))/se_diff

```
$$df=\frac{se_{diff}^{4}}{se_{a}^{4}/(n_a-1)+se_{b}^{4}(n_b-1)}$$
$$df=\frac{(0.8487381)^4}{(0.3144835)^4/(4)+(0.7883251)^4/(4)} = 5.24169$$

```{r}

(se_diff^4)/(((se_x^4)/4)+((se_y^4)/4))
```

```{r}
qt(0.975,5.24169)
qt(0.025,5.24169)

# double checking my work
t.test(xfirst5, yfirst5)
```

The rejection range is any t statistic greater than 2.54 or less than -2.54. The t-statistic from this study (0.08513318) does not fall in the rejection range (using a p-value of 0.05) so we cannot reject the null hypothesis and cannot say that the two means are sufficiently different.


c. Using R, test whether the mean of Y is significantly different from 0.

```{r}
t.test(y,alternative="two.sided",mu=0)
```

```{r}
# rejection region with 2-tailed test
qt(0.975,99)
qt(0.025,99)
```

The rejection range is any t statistic greater than 1.98 or less than -1.98. The t-statistic from this study (-0.24256) does not fall in the rejection range (using a p-value of 0.05) so we cannot reject the null hypothesis. The p-value also tells us that we cannot reject the null. We cannot say that the two means are sufficiently different.


d. Again using the first five observations, test by hand whether the mean of Y is different from 0.

```{r}
# already have first 5 observations from y
yfirst5
```

$$Test\ Statistic = \frac{\overline{yfirst5}-\mu_0}{se} = \frac{-0.3468177-0}{(\frac{1.762748}{\sqrt{5}})} = -0.4399425$$

```{r}
mean(yfirst5)

se_yfirst5 <- sd(yfirst5)/(sqrt(5))

# t-statistic
mean(yfirst5)/se_yfirst5

```

```{r}
qt(0.975,4)
qt(0.025,4)
```

The rejection region is any t statistic greater than 2.77 or less than -2.77. Our t-statistic (-0.4399425) does not fall in the rejection range (using a p-value of 0.05) so we cannot reject the null hypothesis that the mean is 0.

```{r}
# double checking
t.test(yfirst5,alternative="two.sided",mu=0)
```


e. Assuming the mean and sd of Y that you calculate from the first five observations would not change,
what is the minimum total number of observations you would need to be able to conclude that the
mean of Y is different from 0 at the p = 0.01 confidence level?

```{r}
# with an alpha of .01 now

for (i in 5:1000) {
# Recalculate the standard error and CI
stand_err <- (sd(yfirst5)) / sqrt(i)
ci <- mean(yfirst5) + c(qt(.01/2, i-1), qt(1-.01/2, i-1))*stand_err

if (ci[2] < 0)
break # condition met, leave the for loop
}

i



```

You would need to sample 176 people at this confidence level


f. Verify (d) (approximately) by increasing the simulated data to the n you calculated in (e) that would
be necessary. If the test of Y = 0 is still not significant, explain why. (Go back to using the original
100-observation dataset for g and h.)

```{r}
# new standard error
se_y_new <- sd(yfirst5)/(sqrt(176))

# new t-statistic
new_t_stat <- mean(yfirst5)/se_y_new

# new rejection region
qt(0.995,176)
qt(0.005,176)

new_t_stat
```

The new t-statistic is just below the lower threshold, meaning it falls in the rejection region. The p-value confirms, as it is just below .01.

```{r}
# new p-value
pt(new_t_stat, i-1)*2
```


g. Create a categorical (factor) variable c, where c = 1 if x < -1, c = 3 if x > 1, and c = 2 otherwise. Use
R to perform an F test for whether the mean of y differs across these three groups.

```{r}
# combine x and y into a dataframe so we can add c
data <- data.frame(x,y)

# adding c
data_2 <- mutate(data, c = if_else(x < -1, 1,if_else(x > 1, 3, 2)))

# turning c into a factor
c <- data_2$c 
  
c <- factor(c)

data_3 <- data.frame(x,y,c)

# now run the f-test
aov.final = aov(y~c,data=data_3) 
summary(aov.final)
```

The p-value is much less than 0.05, and therefore we reject that the means of all three groups are the same, in favor of the alternative hypothesis that at least one of them is different.


h. Using the first three observations for each group, calculate the same F test by hand.
 
```{r}
# create table with first 3 observations from each c group
c1 <- filter(data_3, c == "1")
c2 <- filter(data_3, c == "2")
c3 <- filter(data_3, c == "3")

c1y <- c1$y[1:3]
c2y <- c2$y[1:3]
c3y <- c3$y[1:3]



csample1 <- data.frame(c = c("1"), y = c1y)
csample2 <- data.frame(c = c("2"), y = c2y)
csample3 <- data.frame(c = c("3"), y = c3y)

sample <- rbind(csample1, csample2, csample3)

# calculate mean and sds 
mean_sample <- mean(sample$y)
sd_sample <- sd(sample$y)

mean_c1 <- mean(filter(sample, c == "1")$y)
mean_c2 <- mean(filter(sample, c == "2")$y)
mean_c3 <- mean(filter(sample, c == "3")$y)

sd_c1 <- sd(filter(sample, c == "1")$y)
sd_c2 <- sd(filter(sample, c == "2")$y)
sd_c3 <- sd(filter(sample, c == "3")$y)

mean_sample
mean_c1
mean_c2
mean_c3
sd_c1
sd_c2
sd_c3
```

Calculate the F-statistic:
$$F-statistic = \frac{average\ variance\ between\ groups}{average\ variance\ within\ groups} $$

$$Between\ variance = \frac{n_1(\overline{y}_1-\overline{y})^2+...+n_G(\overline{y}_G-\overline{y})^2}{G-1}$$

$$Within\ variance = \frac{(n_1-1)s_1^2+...+(n_G-1)s_G^2}{N-G}$$
$$Between\ variance = \frac{3(-3.34-(-0.46))^2+3(-0.68-(-0.46))^2+3(2.6359-(-0.46))^2}{3-1}=26.88391$$


$$Within\ variance = \frac{(3-1)(2.43)^2+(3-1)(2.12)^2+(3-1)(2.89)^2}{9-3} = 6.250291$$

$$F=\frac{26.88391}{6.250291}=4.301225$$

Now calculate the threshold F value to indicate where the tail is (using a tail of 5%):
$$df_1=G-1=2\ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ df_2=N-G=6$$
$$Threshold\ value\ with\ \alpha=0.05 = 5.143253$$
```{r}
# Between variance
((3*(mean_c1-mean_sample)^2)+(3*(mean_c2-mean_sample)^2)+(3*(mean_c3-mean_sample)^2))/2

# Within variance
((2*(sd_c1^2))+(2*(sd_c2^2))+(2*(sd_c3^2)))/6

# F-stat
26.88391/6.250291

#Threshold F value
qf(0.95,2,6)

#p-value
1-pf(4.301225,2,6)
```

Based on both the threshold value and the p-value, we cannot reject that the means of all three groups are the same.


3. Generate a new 100-observation dataset as before, except now y = 0.1 + 0.2 ??? x + e

```{r}
set.seed(28)
x <- rnorm(100, 0, 1)

set.seed(29)
epsilon <- rnorm(100,0,1)

y <- 0.1 + 0.2*x + epsilon
```

a. Regress y on x using R, and report the results.

```{r}
yx_model <- lm(y~x)
summary(yx_model)
```

The R^2 value is very low, so we can say that not much of the variance is explained by our model. There appears to be a positive significant relationship between the variables, as the p-value for x is below .05 and the coefficient is positive. 

b. Discuss the coefficient on x and its standard error, and present the 95% CI.

The coefficient on x from our regression is relatively close to the true coefficient from the equation. The error on x is relatively small.

```{r}
confint(yx_model)
```

Our confidence interval for the coefficient of x (0.08 - 0.48) does not contain 0 so we can conclude that it is significantly different from 0 (because we are 95% confident the coefficient of x will fall within this range).


c. Use R to calculate the p-value on the coefficient on x from the t value for that coefficient. What does
this p-value represent (be very precise in your language here)?

```{r}
p_val <- pt(2.786, 98, lower.tail=F)*2

p_val
```
The p-value is below 0.05, so the coefficient of x is significant at the alpha = 0.05 level.


d. Discuss the F-statistic and its p-value, and calculate that p-value from the F statistic using R. What
does this test and its p-value indicate?

The F-statistic is another indicator of the overall significance of the model. We are testing whether the x coefficient is significantly different from 0.
```{r}
# f = (r2/k) / ((1-r2)/(n-k-1))

f <- (0.07338/1) / ((1-0.07338)/(98))
f

# p-value
pf(7.760722,1,98,lower.tail=F)
```

The p value for the F test is extremely low and the same as the coefficient of x p-value because there is only one variable being run in this analysis.


e. Using the first five observations, calculate by hand the coefficient on x, its standard error, and the
adjusted R2. Be sure to show your work.

```{r}
x_first5 <- x[1:5]
y_first5 <- y[1:5]

x_first5
y_first5
```

Coefficient on X

$$\beta_1 = \frac{Cov(y,x)}{Var(y)} = \frac{0.2852973}{1.087151} = 0.2624265$$

```{r}
cov(y,x)
var(y)

(cov(y,x)/var(y))

```

Standard Error 

$$se_{\beta_1} = se_{{y}} \frac{1}{\sqrt{\sum(x-\overline{x})^2}} = 0.1037422$$


```{r}
#seB1
sd(y)*(1/(sqrt(sum((x-mean(x))^2))))

```


R^2

$$TSS = \sum_i (x_i-\overline{x})^2 = 101.0135$$


$$SSE = \sum_i (x_i-{y}_i)^2 = 152.1526$$

$$R^2 = \frac{TSS-SSE}{TSS} = -0.5062605$$
```{r}
tss <- sum((x - mean(x))^2)
tss

sse <- sum((x - y)^2)
sse

r_sq <- (tss - sse) / tss
r_sq

```


4. Now generate y = 0.1 + 0.2 ??? x ??? 0.5 ??? x^2 + e with 100 observations.

```{r}
set.seed(33)
x <- rnorm(100, 0, 1)

set.seed(34)
epsilon <- rnorm(100,0,1)

x2 <- x*x

y <- 0.1 + 0.2*x - 0.5*x2 + epsilon
```


a. Regress y on x and x^2 and report the results. If x or x^2 are not statistically significant, suggest why.

```{r}
quadreg <- lm(y ~ x + x2)
summary(quadreg)
```

As you can see, the coefficients for both x and x^2 are both relatively close to the true coeficients. The p-value for x is above .05 so it is not significant but the p-value for x^2 is below 0.05 (it is statistically significant). X might not be significant because it's coefficient is so close to 0, so the model didn't determine that it is significantly different from 0.

The x^2 coefficient is negative so the curve is concave. Since the p-value for x^2 is below .05, there is a significant curved effect.


b. Based on the known coefficients that we used to create y, what is the effect on y of increasing x by 1
unit from 1 to 2?

```{r}
# y = 0.1 + 0.2*x - 0.5*x^2

# at x = 1
0.1 + 0.2 - 0.5
# y = -0.2

# at x = 2
0.1 + (0.2*2) - (0.5*(2^2))
# y = -1.5
```

when increasing x from 1 to 2, y decreases by 1.3 units


c. Based on the coefficients estimated from 4(a), what is the effect on y of changing x from -0.5 to -0.7?

```{r}
# y = 0.27948 + 0.11597 * x - 0.68023 * x^2

# at x = -.5
0.27948 + (0.11597*-.5) - (0.68023*(-.5^2))
# y = 0.3915525

# at x = -.7
0.27948 + (0.11597*-.7) - (0.68023*(-.7^2))
# y = 0.5316137
```

y increases by 0.14 (from .39 to .53)


5. Now generate x_2 as a random normal variable with a mean of -1 and a sd of 1. Create a new dataset
where y = 0.1 + 0.2 ??? x ??? 0.5 ??? x * x_2 + e

```{r}
set.seed(35)
x_2 <- rnorm(100,-1,1)

y <- 0.1 + (0.2*x) - (.5 * x * x_2) + epsilon
# using the same x and epsilon random numbers we generated in #4
```


a. Based on the known coefficients, what is the effect of increasing x_2 from 0 to 1 with x held at its mean?

```{r}
mean(x)
# at x_2 = 0  and x = 0.05949108
0.1 + (0.2*0.05949108) - (0.5*0.05949108*0)
# y =  0.1118982

# at x_2 = 1 and x = 0.05949108
0.1 + (0.2*0.05949108) - (0.5*0.05949108*1)
# y = 0.08215268
```

y decreases by 0.03 (from 0.11 to 0.08)


b. Regress y on x, x_2, and their interaction. Based on the regression-estimated coefficients, what is the
effect on y of shifting x from -0.5 to -0.7 with x_2 held at 1?

```{r}
intreg <- lm(y ~ x + x_2 + x*x_2)
summary(intreg)
```
```{r}
# equation based on coefficients  y = 0.08169 + 0.08534x - 0.03031x_2 - 0.46205(x)(x_2)

# at x = -0.5 and x_2=1
0.08169 + (0.08534*-.5) + (-0.03031*1) - (0.46205*-.5*1)
# y = 0.239735

# at x = -0.7 and x_2=1
0.08169 + (0.08534*-.7) + (-0.03031*1) - (0.46205*-.7*1)
# y = 0.315077

```

Y increases by 0.08 (from 0.24 to 0.32)


c. Regress the current y on x alone. Using the R2 from this regression and the R2
from 5(b), perform by hand an F test of the complete model (5b) against the reduced, bivariate model. What does this test
tell you?

```{r}
xreg <- lm(y ~ x)
summary(xreg)
```

```{r}
# f statistic
r2complete <- summary(intreg)$r.squared
r2reduced <- summary(xreg)$r.squared

fstat <- ((r2complete - r2reduced) / 2) / ((1 - r2complete) / (100 - 3 - 1))
fstat

# p value
pf(fstat,2,96,lower.tail=F)
```

The p-value is well below 0.05. This shows that the additional variables in the complete model (x_2 and x*x_2) definitely both belong in the regression as they significantly improve the model.


6. Generate a new variable y_2 using the data from (5) which is 1 if y > 0 and 0 otherwise.

```{r}
# combine x and y into a dataframe so we can add c
df_y2 <- data.frame(y,x,x_2)

# adding y_2
df_y2 <- mutate(df_y2, y_2 = if_else(y > 0, 1, 0))

```


a. Perform a logistic regression of y2 on x, x2, and their interaction, and interpret the results.

```{r}
logreg <- glm(y_2 ~ x + x_2 + x*x_2, data = df_y2, family="binomial")
summary(logreg)
```

From the results, you can see that the two independent variable x and x_2 are not significant but the interaction term of these 2 variables has a significant negative relationship with y_2. X has a positive coefficient while x_2 has a negative coefficient. The interaction variable has the strongest effect on y_2. 

b. What is the effect of increasing x_2 from 0 to 1 with x held at its mean on the probability that y_2 is 1?

First calculate the mean of x

```{r}
mean(df_y2$x)
```
 
Now we can plug these values (and the coefficients from the regression results) into the formula below to find the probability of y_2 being 1 when x_2 is 0. 

$$\hat{P}(y_2=1) = \frac{e^{(\beta_0+\beta_1x_1...)}}{1+ e^{(\beta_0+\beta_1x_1...)}}$$

at x_2 = 0 and x = 0.05949108

$$\hat{P}(y_2=1)= \frac{e^{(0.2350+(0.4680*0.05949108)+(-0.2392*0)+(-0.5019*(0.05949108 * 0)))}}{1+e^{(0.2350+(0.4680*0.05949108)+(-0.2392*0)+(-0.5019*(0.05949108 * 0)))}} = 0.565328$$


```{r}
2.718^(0.2350+(0.4680*0.05949108)+(-0.2392*0)+(-0.5019*(0.05949108 * 0)))/(1+2.718^(0.2350+(0.4680*0.05949108)+(-0.2392*0)+(-0.5019*(0.05949108 * 0))))
```

The probability here is 0.565328

Now plug same values into equation but set x_2 = 1

$$\hat{P}(y_2=1)= \frac{e^{(0.2350+(0.4680*0.05949108)+(-0.2392*1)+(-0.5019*(0.05949108 * 1)))}}{1+e^{(0.2350+(0.4680*0.05949108)+(-0.2392*1)+(-0.5019*(0.05949108 * 1)))}} = 0.498446$$


```{r}
2.718^(0.2350+(0.4680*0.05949108)+(-0.2392*1)+(-0.5019*(0.05949108 * 1)))/(1+2.718^(0.2350+(0.4680*0.05949108)+(-0.2392*1)+(-0.5019*(0.05949108 * 1))))
```

By increasing x_2 from 0 to 1 while keeping x constant at it's mean, the probability that y_2 = 1 decreases by about 7% (from 0.57 to 0.50).


7. Generate a dataset with 300 observations and three variables: f, x1, and x2. f should be a factor with
three levels, where level 1 corresponds to observations 1-100, level 2 to 101-200, and level 3 to 201-300.
(Eg, f can be "a" for the first 100 observations, "b" for the second 100, and "c" for the third 100.)
Create x1 such that the first 100 observations have a mean of 1 and sd of 2; the second 100 have a mean
of 0 and sd of 1; and the third 100 have a mean of 1 and sd of 0.5. Create x2 such that the first 100
observations have a mean of 1 and sd of 2; the second 100 have a mean of 1 and sd of 1; and the third
100 have a mean of 0 and sd of 0.5. (Hint: It is probably easiest to create three 100-observation datasets
first, and then stack them with rbind(). And make sure to convert f to a factor before proceeding.)

```{r}
# creating table
set.seed(41)
x1a <- rnorm(100,1,2) 
set.seed(42)
x1b <- rnorm(100,0,1)
set.seed(43)
x1c <- rnorm(100,1,.5)

set.seed(44)
x2a <- rnorm(100,1,2)
set.seed(45)
x2b <- rnorm(100,1,1)
set.seed(46)
x2c <- rnorm(100,0,.5)

dfa <- data.frame(f = "a", x1 = x1a, x2 = x2a)
dfb <- data.frame(f = "b", x1 = x1b, x2 = x2b)
dfc <- data.frame(f = "c", x1 = x1c, x2 = x2c)

dfabc <- rbind(dfa, dfb, dfc)
```


a. Using the k-means algorithm, peform a cluster analysis of these data using a k of 3 (use only x1 and
x2 in your calculations; use f only to verify your results). Comparing your clusters with f, how many
datapoints are correctly classified into the correct cluster? How similar are the centroids from your
analysis to the true centers?

```{r}
#perform the analysis
kout <- kmeans(dfabc[,2:3], centers=3, nstart=25)


# now look at the clustered groups compared to f 
clustervector <- kout$cluster

fgroups <- dfabc$f

# judging by the groupings in clustervector, I'm guessing which of 1, 2, and 3 correspond to a, b, and c in original table
fgroups <- ifelse(fgroups == "a", 1, ifelse(fgroups == "b", 3, 2))

clusterscorrect <- sum(fgroups == clustervector)
clusterscorrect
# 181 match


# how similar are the centroids

# true centroids
# get centroids of groups
centroidsdf <- aggregate(dfabc[,2:3],by=list(cat=dfabc$f),FUN=mean) 

# centroids from kmeans
centroidsk <- kout$centers

centroidsdf
centroidsk

```


b. Perform a factor analysis of this data using your preferred function. Using the scree plot, how many
factors do you think you should include? Speculate about how these results relate to those you got
with the cluster analysis.

```{r}
# Princomp method
dfabc_pca <- princomp(dfabc[,2:3])
dfabc_pca

# scree plot
plot(dfabc_pca,type="lines")
```

There are only 2 factors and both should be kept because they explain a good amount of variance


8. Generate a dataset of 200 observations, this time with 90 independent variables, each of mean 0 and sd 1. Create y such that: y = 2x1 + ... + 2x30 ??? x31 ??? ... ??? x60 + 0 ??? x61 + ... + 0 ??? x90 + e

where e is a random normal variable with mean 0 and sd 10. (Ie, the first 30 x's have a coefficient of 2; the next 30 have a coefficient of -1; and the last 30 have a coefficient of 0.)

```{r}
library(mvtnorm)

set.seed(81)
coefs <- rep(c(2, -1, 0), each=30)
mu <- rnorm(200, 0, 10)
m <- rep(0, 90) # mean of independent variables
sig <- diag(90) # cov of indep variables
x <- rmvnorm(200, mean=m, sigma=sig) # generates 200 observations from multivariate normal 
y <- x%*%coefs + mu
```


a. Perform an elastic net regression of y on all the x variables using just the first 100 observations. Use
10-fold cross-validation to find the best value of lambda and approximately the best value of alpha.

```{r}
library(glmnet)

x_in_sample <- x[1:100, ]
y_in_sample <- y[1:100]
x_out_sample <- x[101:200, ]
y_out_sample <- y[101:200]

lambdalevels <- 10^seq(7,-2,length=100)

# running it at different alpha levels

#lasso
set.seed(1)
cv.lasso.mod=cv.glmnet(x_in_sample,y_in_sample,alpha=1,lambda=lambdalevels)
plot(cv.lasso.mod)
# best fit is with about 30 coefficients. We do one standard dev worse with a model with around 15

#ridge
set.seed(1)
cv.ridge.mod=cv.glmnet(x_in_sample,y_in_sample,alpha=0,lambda=lambdalevels)
plot(cv.ridge.mod)
# all 90 coefficients

#combo
set.seed(1)
cv.combo.mod=cv.glmnet(x_in_sample,y_in_sample,alpha=.5,lambda=lambdalevels)
plot(cv.combo.mod)
# about 50 coefficients

# will use alpha =1
# now find best lambda
lasso.mod=glmnet(x_in_sample,y_in_sample,alpha=1,lambda=lambdalevels)
plot(lasso.mod,xvar="lambda")

bestlambda <- cv.lasso.mod$lambda.min
bestlambda
```


b. How accurate are your coefficients from (a)? Summarize your results any way you like, but please don't
give us the raw coefficients from 90 variables.

```{r}
# get the coefficients
bestcoeff <- predict(lasso.mod, type="coefficients",s=bestlambda)

actualcoeff <- c(0,rep(2,30),rep(-1,30),rep(0,30))

mse <- mean(bestcoeff[,1]-actualcoeff)^2
mse
```

This doesn't seem very accurate

c. Using the results from (b), predict y for the second 100 observations. How accurate is your prediction?

```{r}
y_predicted <- predict(cv.lasso.mod$glmnet.fit, s=cv.lasso.mod$lambda.min, newx=x_out_sample)

mse.lasso <- sum((y_out_sample - y_predicted)^2)/nrow(x_out_sample)
mse.lasso

plot(y_predicted, y_out_sample)

```

It looks relatively accurate


d. Attempt to compare the predictive accuracy here to the accuracy of a prediction made using regular
multiple regression. Explain your results, including if the regular regression failed for any reason.

```{r}
# regression
lmout <- lm(y_in_sample~x_in_sample)
y_predicted_reg <- cbind(1,x_out_sample) %*% lmout$coefficients

mse.reg <- sum((y_out_sample - y_predicted_reg)^2)/nrow(x_out_sample)
mse.reg

plot(y_predicted_reg, y_out_sample)

```

The Lasso regression has a lower mse and appears to be more accurate when plotted.



9. As in problem 6, use the data from 8 to generate a new y_2 that is 1 if y > 0 and 0 otherwise.

```{r}
y_2  <- as.factor(ifelse(y >0, 1, 0))
```

a. Using the same process as in 8, estimate an SVM model of y_2 on all the x variables for the first 100
variables. Use 10-fold cross-validation to select the best kernel.

```{r}
# create in/out sample for y_2
y_2_in_sample <- y_2[1:100]
y_2_out_sample <- y_2[101:200]


library(e1071)

in_sample_data <- data.frame(y=y_2_in_sample, x_in_sample)

costvalues <- 10^seq(-3,2,1)

# run it for linear kernel
tuned_svm_linear <- tune(svm, y~., data=in_sample_data, ranges=list(cost=costvalues), kernel="linear")
summary(tuned_svm_linear)
```

```{r}
# run it for radial kernel
tuned_svm_radial <- tune(svm, y~., data=in_sample_data, ranges=list(cost=costvalues), kernel="radial")
summary(tuned_svm_radial)
```

Radial is slightly better

b. Using the results from (a), predict y_2 for the second 100 observations, and report your accuracy.

```{r}
out_sample_data <- data.frame(y=y_2_out_sample, x_out_sample)

y_pred_svm <- predict(tuned_svm_radial$best.model,newdata=out_sample_data)

#percent correct
sum(y_pred_svm==out_sample_data$y)/length(out_sample_data$y)
```


 

